{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration\n",
    "---\n",
    "Calibration refers to the statistical consistency between the distributional forecasts and the observations and is a joint property of the predictions and the events that materialize. It intuitively means that whenever a forecaster assigns a probability of 0.8 to an event, that event should occur about 80% of the time. Not overconfident and well-calibrated model is essential for safe decision making.\n",
    "\n",
    "Calibrating a classifier consists in fitting a regressor (called a calibrator) that maps the output of the classifier (as given by predict or predict_proba) to a calibrated probability in [0, 1].\n",
    "\n",
    "### Table of Contents\n",
    "- [Platt Scaling](#logistic_calib)\n",
    "- [Isotonic Regression](#Isotonic_calib)  \n",
    "- [References](#references)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='logistic_calib'></a>\n",
    "## Platt Scaling\n",
    "---\n",
    "It is logistic calibration, a method for transforming SVM outputs from $[-\\infty, +\\infty]$ to posterior probabilities. Platt Scaling is most effective when the distortion in the predicted probabilities is sigmoid-shaped.\n",
    "\n",
    "\n",
    "Let the output of a learning method be $f(x)$. To get calibrated probabilities, pass the output through a sigmoid:    \n",
    "<br>  \n",
    "<div align=\"center\">  \n",
    "    $$P(y=1|f) = \\frac{1}{1+exp(Af+B)}$$\n",
    "</div>\n",
    "  \n",
    "where the parameters $A$ and $B$ are fitted using maximum likelihood estimation from a fitting training set $(f_{i},y_{i})$. Gradient descent is used to find $A$ and $B$ such that they are the solution to:\n",
    "\n",
    "<div align=\"center\">\n",
    "    $$\\underset{A,B}{argmin}\\{ - \\underset{i}{\\sum} y_{i}log(p_{i}) + (1-y_{i})log(1-p_{i}) \\},$$\n",
    "</div>\n",
    "\n",
    "where        \n",
    "    \n",
    "\n",
    "<div align=\"center\">\n",
    "    $$p_{i} = \\frac{1}{1+exp(Af_{i}+B)}$$\n",
    "</div>\n",
    "  \n",
    "To avoid overfitting to the sigmoid train set, an out-of-sample model is used. If there are $N_{+}$ positive examples and $N_{-}$ negative examples in the train set, for each training example Platt Calibration uses target values $y_{+}$ and $y_{-}$ (instead of 1 and 0, respectively), where\n",
    "  \n",
    "  \n",
    "<div align=\"center\">\n",
    "    $$y_{+} = \\frac{N_{+}+1}{N_{+}+2}; y_{-}=\\frac{1}{N_{-}+2}$$\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "<a id='isotonic_calib'></a>\n",
    "## Isotonic Regression\n",
    "---\n",
    "The method to calibrate predictions from boosted naive bayes, SVM, and decision tree models. Isotonic Regression is a powerful calibration method that can correct any monotonic distortion.  \n",
    "Given the prediction $f_{i}$ from a model and the true targets $y_{i}$, the basic assumption in Isotonic Regression is that:\n",
    "\n",
    "<div align=\"center\">\n",
    "    $$y_{i} = m(f_{i})+\\epsilon_{i}$$\n",
    "</div>\n",
    "\n",
    "where $m$ is an isotonic (monotonically increasing) function. Then, given a train set $(f_{i},y_{i})$, the Isotonic Regression problem is finding the isotonic function $\\hat{m}$ such that\n",
    "\n",
    "<div align=\"center\">\n",
    "    $$\\hat{m}=argmin_{z}\\sum(y_{i}-z(f_{i}))^{2}$$\n",
    "</div>\n",
    "\n",
    "As in the case of Platt calibration, we use an independent validation set to train the isotonic function.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "<a id='binnig_calib'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='beta_calib'></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='references'></a>\n",
    "## References\n",
    "---\n",
    "[1] Gneiting, Tilmann, Fadoua Balabdaoui, and Adrian E. Raftery. \"Probabilistic forecasts, calibration and sharpness.\" Journal of the Royal Statistical Society: Series B (Statistical Methodology) 69.2 (2007): 243-268. ([link](https://sites.stat.washington.edu/raftery/Research/PDF/Gneiting2007jrssb.pdf))\n",
    "\n",
    "[2] Kuleshov, Volodymyr, Nathan Fenner, and Stefano Ermon. \"Accurate uncertainties for deep learning using calibrated regression.\" arXiv preprint arXiv:1807.00263 (2018). ([link](https://arxiv.org/abs/1807.00263))\n",
    "\n",
    "[3] Niculescu-Mizil, Alexandru, and Rich Caruana. \"Predicting good probabilities with supervised learning.\" Proceedings of the 22nd international conference on Machine learning. 2005. ([linke](https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}